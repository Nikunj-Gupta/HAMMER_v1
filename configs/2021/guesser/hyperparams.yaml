main:
  gamma: 0.95  # discount factor
  eps_clip: 0.2  # clip parameter for PPO 
local:
  actor_layer: [10, 10]  # number of variables in hidden layer
  critic_layer: [10, 10]
  update_timestep: 100  # update policy every n timesteps
  lr: 0.0003
  K_epochs: 8  # update policy for K epochs
global:
  update_timestep: 100  # update policy every n timesteps
  action_std: 0.5  # constant std for action distribution (Multivariate Normal)
  K_epochs: 8  # update policy for K epochs
  lr: 0.0003  # parameters for Adam optimizer
  actor_layer: [10, 10] # number of variables in hidden layer
  critic_layer: [10, 10] 