main:
  exp_name: "multiwalker-baseline-walkers5"
  n_walkers: 5
  log_dir: "logs/"
  save_dir: "save-dir/"
  log_interval: 20    # print avg reward in the interval
  max_episodes: 20000 # max training episodes
  max_timesteps: 25  # max timesteps in one episode
  random_seed: 10
  gamma: 0.95  # discount factor
  eps_clip: 0.2  # clip parameter for PPO
  save_interval: 50 # save model in the interval
  message_len: 25
  main: 0
local:
  update_timestep: 4000  # update policy every n timesteps
  action_std: 0.5  # constant std for action distribution (Multivariate Normal)
  K_epochs: 80  # update policy for K epochs
  lr: 0.0003  # parameters for Adam optimizer
  hidden_nodes: 64
global:
  update_timestep: 4000  # update policy every n timesteps
  action_std: 0.5  # constant std for action distribution (Multivariate Normal)
  K_epochs: 80  # update policy for K epochs
  lr: 0.0003  # parameters for Adam optimizer
  hidden_nodes: 64