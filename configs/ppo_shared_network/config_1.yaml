env_name: "Cooperative_Navigation"
exp_name: "ppo_shared_network"
log_dir: "logs/"
max_episodes: 30000
max_steps: 25
n_latent_var: 64  # number of variables in hidden layer
update_timestep: 2000  # update policy every n timesteps
lr: 0.01
gamma: 0.95  # discount factor
K_epochs: 4  # update policy for K epochs
eps_clip: 0.2  # clip parameter for PPO
random_seed: 10